{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eric15342335/realfill/blob/main/train_realfill.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7M37t-cRkNDf",
        "outputId": "c60acbd0-1b0c-4334-94b2-1197871043e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'realfill'...\n",
            "remote: Enumerating objects: 313, done.\u001b[K\n",
            "remote: Counting objects: 100% (97/97), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 313 (delta 66), reused 35 (delta 28), pack-reused 216 (from 1)\u001b[K\n",
            "Receiving objects: 100% (313/313), 1.28 MiB | 3.34 MiB/s, done.\n",
            "Resolving deltas: 100% (137/137), done.\n",
            "/content/realfill\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/eric15342335/realfill\n",
        "%cd realfill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vmLsetScrhad",
        "outputId": "7668e971-14aa-44bc-9d20-324c8bd1b94a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  452M  100  452M    0     0  64.5M      0  0:00:07  0:00:07 --:--:-- 64.5M\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://github.com/eric15342335/realfill/releases/download/dataset/realfill_data_release_full.zip -o realfill_data_release_full.zip\n",
        "!unzip -q realfill_data_release_full.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L https://github.com/eric15342335/realfill/releases/download/dataset/jensen_images.zip -o jensen_images.zip\n",
        "!unzip -q jensen_images.zip"
      ],
      "metadata": {
        "id": "rXUagDd5A69z",
        "outputId": "337fe032-7528-4cc0-a172-2b62f344f79f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 43.5M  100 43.5M    0     0  16.7M      0  0:00:02  0:00:02 --:--:-- 25.5M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wTXUPQrrtMZF",
        "outputId": "18788c18-584a-4e3d-ff4e-9725ca9d357f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 497M\n",
            "drwxr-xr-x 4 root root 4.0K Apr 21 16:03 \u001b[0m\u001b[01;34mdata\u001b[0m/\n",
            "-rw-r--r-- 1 root root 3.4K Apr 21 16:03 infer.py\n",
            "drwxr-xr-x 3 root root 4.0K Apr 22  2025 \u001b[01;34mjensen_images\u001b[0m/\n",
            "-rw-r--r-- 1 root root  44M Apr 21 16:03 jensen_images.zip\n",
            "-rw-r--r-- 1 root root 1.1K Apr 21 16:03 LICENSE\n",
            "drwxr-xr-x 3 root root 4.0K Apr 21 16:03 \u001b[01;34m__MACOSX\u001b[0m/\n",
            "-rw-r--r-- 1 root root  383 Apr 21 16:03 README.md\n",
            "-rw-r--r-- 1 root root 5.9K Apr 21 16:03 README-Realfill.md\n",
            "drwxr-xr-x 4 root root 4.0K May 30  2024 \u001b[01;34mrealfill_data_release_full\u001b[0m/\n",
            "-rw-r--r-- 1 root root 453M Apr 21 16:03 realfill_data_release_full.zip\n",
            "-rw-r--r-- 1 root root  119 Apr 21 16:03 requirements.txt\n",
            "-rw-r--r-- 1 root root 6.4K Apr 21 16:03 train_realfill.ipynb\n",
            "-rw-r--r-- 1 root root  37K Apr 21 16:03 train_realfill.py\n"
          ]
        }
      ],
      "source": [
        "%pwd\n",
        "%ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8hcWLJk3kq3i",
        "outputId": "d32107d9-79bd-4579-fc72-db7af329ab81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mResolved \u001b[1m58 packages\u001b[0m \u001b[2min 560ms\u001b[0m\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m setuptools \u001b[2m(1.2MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m xformers \u001b[2m(41.4MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m bitsandbytes \u001b[2m(72.5MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-curand-cu12 \u001b[2m(53.7MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cusolver-cu12 \u001b[2m(122.0MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cuda-nvrtc-cu12 \u001b[2m(23.5MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cuda-cupti-cu12 \u001b[2m(13.2MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m numpy \u001b[2m(15.7MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-nvjitlink-cu12 \u001b[2m(20.1MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cudnn-cu12 \u001b[2m(634.0MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cusparse-cu12 \u001b[2m(197.8MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cufft-cu12 \u001b[2m(201.7MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m diffusers \u001b[2m(3.4MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pillow \u001b[2m(4.4MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cublas-cu12 \u001b[2m(346.6MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m tensorboard \u001b[2m(5.2MiB)\u001b[0m\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m pillow\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m tensorboard\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m setuptools\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cuda-cupti-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m diffusers\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-nvjitlink-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cuda-nvrtc-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-curand-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m xformers\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m bitsandbytes\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m numpy\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cusolver-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cusparse-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cufft-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cublas-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cudnn-cu12\n",
            "\u001b[2mPrepared \u001b[1m25 packages\u001b[0m \u001b[2min 21.69s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m22 packages\u001b[0m \u001b[2min 215ms\u001b[0m\u001b[0m\n",
            "\u001b[2mInstalled \u001b[1m25 packages\u001b[0m \u001b[2min 58ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mabsl-py\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mabsl-py\u001b[0m\u001b[2m==2.2.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.45.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mdiffusers\u001b[0m\u001b[2m==0.32.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdiffusers\u001b[0m\u001b[2m==0.33.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mftfy\u001b[0m\u001b[2m==6.3.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.2.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.4.5.8\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.1.3\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.5.147\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.1.9\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.3.1.170\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==24.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.15.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.2.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==5.29.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.30.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==5.9.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.0.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==75.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==79.0.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtensorboard\u001b[0m\u001b[2m==2.18.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtensorboard\u001b[0m\u001b[2m==2.19.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxformers\u001b[0m\u001b[2m==0.0.29.post3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install -U -r requirements.txt --no-progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XYgiy8a9k5yA",
        "outputId": "d4b45c99-823d-4fb2-f679-d293c662f6c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.cache/huggingface/accelerate/default_config.yaml')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from accelerate.utils import write_basic_config\n",
        "write_basic_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HaqFewZMrhae",
        "outputId": "a2812cb6-9621-4853-9344-a70a5ee5f573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using Google Drive storage\n",
            "Output directory: /content/drive/MyDrive/RealFill/Custom-35-model\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Toggle switch - set to True for Google Drive storage, False for local storage\n",
        "USE_DRIVE_STORAGE = True\n",
        "# Toggle switch - set to True for FP32 training, False for FP16 (mixed precision)\n",
        "USE_FP32 = False # Set to True to use FP32 precision\n",
        "\n",
        "# Base directory for Google Drive storage\n",
        "DRIVE_BASE_DIR = \"/content/drive/MyDrive/RealFill\"\n",
        "\n",
        "# Keep your original environment variable setup\n",
        "os.environ[\"DATASET\"] = \"jensen_images\" # realfill_data_release_full, jensen_images\n",
        "os.environ[\"MODEL_NAME\"] = \"stabilityai/stable-diffusion-2-inpainting\"\n",
        "os.environ[\"BENCHMARK\"] = \"Custom\"  # RealBench, Qualitative, Custom\n",
        "os.environ[\"DATASET_NUMBER\"] = \"35\"\n",
        "\n",
        "# Construct paths based on the storage toggle\n",
        "if USE_DRIVE_STORAGE:\n",
        "    # Use Google Drive for storage\n",
        "    from google.colab import drive # Original import location\n",
        "    drive.mount('/content/drive') # Original mount call\n",
        "    base_output_prefix = f'{DRIVE_BASE_DIR}/{os.environ[\"BENCHMARK\"]}-{os.environ[\"DATASET_NUMBER\"]}'\n",
        "else:\n",
        "    # Use local Colab storage (original paths)\n",
        "    base_output_prefix = f'{os.environ[\"BENCHMARK\"]}-{os.environ[\"DATASET_NUMBER\"]}'\n",
        "\n",
        "# --- Set output paths directly combining the conditional suffix ---\n",
        "os.environ[\"OUTPUT_DIR\"] = f'{base_output_prefix}-model{\"-fp32\" if USE_FP32 else \"\"}'\n",
        "os.environ[\"OUTPUT_IMG_DIR\"] = f'{base_output_prefix}-results{\"-fp32\" if USE_FP32 else \"\"}'\n",
        "\n",
        "# The remaining variable paths stay the same (Original)\n",
        "os.environ[\"TRAIN_DIR\"] = f'{os.environ[\"DATASET\"]}/{os.environ[\"BENCHMARK\"]}/{os.environ[\"DATASET_NUMBER\"]}'\n",
        "os.environ[\"VAL_IMG\"] = f'{os.environ[\"TRAIN_DIR\"]}/target/target.png'\n",
        "os.environ[\"VAL_MASK\"] = f'{os.environ[\"TRAIN_DIR\"]}/target/mask.png'\n",
        "\n",
        "# Create the necessary directories (Original)\n",
        "os.makedirs(os.environ[\"OUTPUT_DIR\"], exist_ok=True)\n",
        "os.makedirs(os.environ[\"OUTPUT_IMG_DIR\"], exist_ok=True)\n",
        "\n",
        "# --- Set the shell environment variable using os.environ ---\n",
        "# This makes the variable available to the subshell created by !\n",
        "os.environ['PRECISION_ARG'] = '--mixed_precision=fp16' if not USE_FP32 else ''\n",
        "\n",
        "# --- Original Print Statements ---\n",
        "print(f\"Using {'Google Drive' if USE_DRIVE_STORAGE else 'local Colab'} storage\")\n",
        "print(f\"Output directory: {os.environ['OUTPUT_DIR']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQexbUktpzdp",
        "outputId": "4ea48faa-05a8-49bf-ccfa-216ee3861614",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-21 16:04:53.513208: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745251493.532457    3332 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745251493.538298    3332 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-21 16:04:53.557552: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "04/21/2025 16:04:56 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "tokenizer_config.json: 100% 829/829 [00:00<00:00, 7.29MB/s]\n",
            "vocab.json: 100% 1.06M/1.06M [00:00<00:00, 25.1MB/s]\n",
            "merges.txt: 100% 525k/525k [00:00<00:00, 34.0MB/s]\n",
            "special_tokens_map.json: 100% 460/460 [00:00<00:00, 2.86MB/s]\n",
            "scheduler_config.json: 100% 308/308 [00:00<00:00, 2.46MB/s]\n",
            "{'dynamic_thresholding_ratio', 'prediction_type', 'timestep_spacing', 'rescale_betas_zero_snr', 'clip_sample_range', 'variance_type', 'sample_max_value', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
            "config.json: 100% 638/638 [00:00<00:00, 4.96MB/s]\n",
            "model.safetensors: 100% 1.36G/1.36G [00:05<00:00, 255MB/s]\n",
            "config.json: 100% 616/616 [00:00<00:00, 5.50MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:01<00:00, 264MB/s]\n",
            "{'scaling_factor', 'force_upcast', 'mid_block_add_attention', 'latents_std', 'use_post_quant_conv', 'latents_mean', 'use_quant_conv', 'shift_factor'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at stabilityai/stable-diffusion-2-inpainting.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "config.json: 100% 914/914 [00:00<00:00, 8.77MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 3.46G/3.46G [00:20<00:00, 172MB/s]\n",
            "{'addition_embed_type', 'cross_attention_norm', 'time_embedding_type', 'only_cross_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'transformer_layers_per_block', 'num_attention_heads', 'num_class_embeds', 'encoder_hid_dim_type', 'class_embeddings_concat', 'resnet_time_scale_shift', 'mid_block_type', 'conv_in_kernel', 'addition_time_embed_dim', 'conv_out_kernel', 'attention_type', 'upcast_attention', 'mid_block_only_cross_attention', 'time_cond_proj_dim', 'resnet_skip_time_act', 'class_embed_type', 'time_embedding_act_fn', 'resnet_out_scale_factor', 'reverse_transformer_layers_per_block', 'encoder_hid_dim', 'time_embedding_dim', 'timestep_post_act', 'dropout'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing UNet2DConditionModel.\n",
            "\n",
            "All the weights of UNet2DConditionModel were initialized from the model checkpoint at stabilityai/stable-diffusion-2-inpainting.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n",
            "04/21/2025 16:05:37 - INFO - __main__ - ***** Running training *****\n",
            "04/21/2025 16:05:37 - INFO - __main__ -   Num examples = 5\n",
            "04/21/2025 16:05:37 - INFO - __main__ -   Num batches each epoch = 1\n",
            "04/21/2025 16:05:37 - INFO - __main__ -   Num Epochs = 2000\n",
            "04/21/2025 16:05:37 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "04/21/2025 16:05:37 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "04/21/2025 16:05:37 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "04/21/2025 16:05:37 - INFO - __main__ -   Total optimization steps = 2000\n",
            "Checkpoint 'latest' does not exist. Starting a new training run.\n",
            "Steps:   1% 13/2000 [00:31<1:14:35,  2.25s/it, loss=0.074]"
          ]
        }
      ],
      "source": [
        "!accelerate launch train_realfill.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --train_data_dir=$TRAIN_DIR \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=16 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --unet_learning_rate=2e-4 \\\n",
        "  --text_encoder_learning_rate=4e-5 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=100 \\\n",
        "  --max_train_steps=2000 \\\n",
        "  --lora_rank=8 \\\n",
        "  --lora_dropout=0.1 \\\n",
        "  --lora_alpha=16 \\\n",
        "  --resume_from_checkpoint=\"latest\" \\\n",
        "  --report_to tensorboard \\\n",
        "  --validation_steps 100 \\\n",
        "  --checkpointing_steps 100 \\\n",
        "  $PRECISION_ARG \\\n",
        "  --use_8bit_adam \\\n",
        "  --set_grads_to_none \\\n",
        "  --enable_xformers_memory_efficient_attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m023PQGd_H1"
      },
      "outputs": [],
      "source": [
        "!accelerate launch infer.py \\\n",
        "    --model_path=$OUTPUT_DIR \\\n",
        "    --validation_image=$VAL_IMG \\\n",
        "    --validation_mask=$VAL_MASK \\\n",
        "    --output_dir=$OUTPUT_IMG_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm40ryltdVNF"
      },
      "outputs": [],
      "source": [
        "# Zip final inference results\n",
        "!zip -r9j $OUTPUT_IMG_DIR.zip $OUTPUT_IMG_DIR\n",
        "# Zip tensorboard logs\n",
        "!zip -r9D $OUTPUT_DIR-tensorboard.zip $OUTPUT_DIR/logs\n",
        "%ls"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}