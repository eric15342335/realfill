{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eric15342335/realfill/blob/main/train_realfill.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7M37t-cRkNDf",
        "outputId": "e0e96626-8a86-4cb2-999c-3986552ce124",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'realfill'...\n",
            "remote: Enumerating objects: 438, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 438 (delta 7), reused 6 (delta 5), pack-reused 425 (from 1)\u001b[K\n",
            "Receiving objects: 100% (438/438), 20.13 MiB | 19.96 MiB/s, done.\n",
            "Resolving deltas: 100% (210/210), done.\n",
            "/content/realfill\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/eric15342335/realfill\n",
        "%cd realfill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vmLsetScrhad",
        "outputId": "71f6dadd-fe73-49d8-d2ad-a29b68d4327d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  452M  100  452M    0     0  84.4M      0  0:00:05  0:00:05 --:--:-- 95.1M\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://github.com/eric15342335/realfill/releases/download/dataset/realfill_data_release_full.zip -o realfill_data_release_full.zip\n",
        "!unzip -q realfill_data_release_full.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rXUagDd5A69z",
        "outputId": "93924564-ce68-4513-c940-59c6f225d7d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 43.5M  100 43.5M    0     0  28.6M      0  0:00:01  0:00:01 --:--:-- 51.5M\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://github.com/eric15342335/realfill/releases/download/dataset/jensen_images.zip -o jensen_images.zip\n",
        "!unzip -q jensen_images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wTXUPQrrtMZF",
        "outputId": "6d3b5634-702e-4397-c836-ae4b6e218291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 516M\n",
            "drwxr-xr-x 2 root root 4.0K Apr 26 19:48 \u001b[0m\u001b[01;34mbenchmark\u001b[0m/\n",
            "-rw-r--r-- 1 root root  30K Apr 26 19:48 benchmarks.py\n",
            "drwxr-xr-x 4 root root 4.0K Apr 26 19:48 \u001b[01;34mdata\u001b[0m/\n",
            "-rw-r--r-- 1 root root 3.4K Apr 26 19:48 infer.py\n",
            "drwxr-xr-x 3 root root 4.0K Apr 22 00:01 \u001b[01;34mjensen_images\u001b[0m/\n",
            "-rw-r--r-- 1 root root  44M Apr 26 19:49 jensen_images.zip\n",
            "-rw-r--r-- 1 root root 1.1K Apr 26 19:48 LICENSE\n",
            "-rw-r--r-- 1 root root  19K Apr 26 19:48 loftr_ranking.py\n",
            "drwxr-xr-x 3 root root 4.0K Apr 26 19:48 \u001b[01;34m__MACOSX\u001b[0m/\n",
            "-rw-r--r-- 1 root root 7.8K Apr 26 19:48 README.md\n",
            "-rw-r--r-- 1 root root 5.9K Apr 26 19:48 README-Realfill.md\n",
            "drwxr-xr-x 4 root root 4.0K May 30  2024 \u001b[01;34mrealfill_data_release_full\u001b[0m/\n",
            "-rw-r--r-- 1 root root 453M Apr 26 19:48 realfill_data_release_full.zip\n",
            "-rw-r--r-- 1 root root  20M Apr 26 19:48 Realfill.pdf\n",
            "-rw-r--r-- 1 root root  342 Apr 26 19:48 requirements-benchmarks.txt\n",
            "-rw-r--r-- 1 root root  126 Apr 26 19:48 requirements.txt\n",
            "-rw-r--r-- 1 root root  17K Apr 26 19:48 train_realfill.ipynb\n",
            "-rw-r--r-- 1 root root  37K Apr 26 19:48 train_realfill.py\n"
          ]
        }
      ],
      "source": [
        "%pwd\n",
        "%ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8hcWLJk3kq3i",
        "outputId": "fa78cc0a-2715-4d58-bbed-96287373b63a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mResolved \u001b[1m60 packages\u001b[0m \u001b[2min 437ms\u001b[0m\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cublas-cu12 \u001b[2m(346.6MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cudnn-cu12 \u001b[2m(634.0MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-curand-cu12 \u001b[2m(53.7MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cufft-cu12 \u001b[2m(201.7MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cuda-cupti-cu12 \u001b[2m(13.2MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cusolver-cu12 \u001b[2m(122.0MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cusparse-cu12 \u001b[2m(197.8MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cuda-nvrtc-cu12 \u001b[2m(23.5MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-nvjitlink-cu12 \u001b[2m(20.1MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m kornia \u001b[2m(1.0MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m xformers \u001b[2m(41.4MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m kornia-rs \u001b[2m(2.0MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m bitsandbytes \u001b[2m(72.5MiB)\u001b[0m\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m kornia-rs\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cuda-cupti-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-nvjitlink-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cuda-nvrtc-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m kornia\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m xformers\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-curand-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m bitsandbytes\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cusolver-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cusparse-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cufft-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cublas-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cudnn-cu12\n",
            "\u001b[2mPrepared \u001b[1m15 packages\u001b[0m \u001b[2min 26.68s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m10 packages\u001b[0m \u001b[2min 30ms\u001b[0m\u001b[0m\n",
            "\u001b[2mInstalled \u001b[1m15 packages\u001b[0m \u001b[2min 22ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.45.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mftfy\u001b[0m\u001b[2m==6.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkornia\u001b[0m\u001b[2m==0.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkornia-rs\u001b[0m\u001b[2m==0.1.8\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.4.5.8\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.1.3\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.5.147\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.1.9\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.3.1.170\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxformers\u001b[0m\u001b[2m==0.0.29.post3\u001b[0m\n",
            "\u001b[2mUsing Python 3.11.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mResolved \u001b[1m27 packages\u001b[0m \u001b[2min 800ms\u001b[0m\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m numpy \u001b[2m(15.6MiB)\u001b[0m\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m numpy\n",
            "\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 361ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 46ms\u001b[0m\u001b[0m\n",
            "\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 17ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.1.2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install -r requirements.txt --no-progress\n",
        "!uv pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124 --no-progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XYgiy8a9k5yA",
        "outputId": "9710955f-e682-417a-fdf5-6017a9c6b188",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.cache/huggingface/accelerate/default_config.yaml')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from accelerate.utils import write_basic_config\n",
        "\n",
        "write_basic_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaqFewZMrhae"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Configuration Toggles ---\n",
        "USE_DRIVE_STORAGE = True  # True: Use Google Drive; False: Use local Colab storage\n",
        "USE_FP32 = False  # True: Use FP32 precision; False: Use FP16 (mixed)\n",
        "USE_GENERATED_REF_IMAGE = False  # True: Supplement refs using prior results via LoFTR script\n",
        "TARGET_TOTAL_REF_COUNT = 5  # Desired final number of reference images\n",
        "\n",
        "# --- Base Environment Setup ---\n",
        "DRIVE_BASE_DIR = \"/content/drive/MyDrive/RealFill\"  # Base path on Google Drive\n",
        "\n",
        "# --- Dataset and Model Info ---\n",
        "# Possible values: realfill_data_release_full, jensen_images, your_custom_dataset\n",
        "os.environ[\"DATASET\"] = \"realfill_data_release_full\"\n",
        "os.environ[\"MODEL_NAME\"] = \"stabilityai/stable-diffusion-2-inpainting\"\n",
        "# Possible values: RealBench, Qualitative, Custom\n",
        "os.environ[\"BENCHMARK\"] = \"RealBench\"\n",
        "os.environ[\"DATASET_NUMBER\"] = \"22\"  # Important: Set your dataset number\n",
        "\n",
        "# --- Path to the LoFTR script ---\n",
        "# Assumes loftr_ranking.py is in the current working directory of the notebook\n",
        "LOFTR_SCRIPT_PATH = \"loftr_ranking.py\"  # Adjust if it's in a subfolder. loftr_ranking.py\n",
        "\n",
        "print(\"Configuration Loaded.\")\n",
        "\n",
        "# --- Determine Base Output Prefix (Drive or Local) ---\n",
        "base_output_prefix = \"\"\n",
        "if USE_DRIVE_STORAGE:\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "\n",
        "        drive.mount(\"/content/drive\", force_remount=True)\n",
        "        print(\"Google Drive mounted.\")\n",
        "        base_output_prefix = f'{DRIVE_BASE_DIR}/{os.environ[\"BENCHMARK\"]}-{os.environ[\"DATASET_NUMBER\"]}'\n",
        "        Path(DRIVE_BASE_DIR).mkdir(parents=True, exist_ok=True)\n",
        "    except Exception as e:\n",
        "        print(f\"WARNING: Drive mount/access failed ({e}). Falling back to local.\")\n",
        "        USE_DRIVE_STORAGE = False\n",
        "        base_output_prefix = f'{os.environ[\"BENCHMARK\"]}-{os.environ[\"DATASET_NUMBER\"]}'\n",
        "else:\n",
        "    base_output_prefix = f'{os.environ[\"BENCHMARK\"]}-{os.environ[\"DATASET_NUMBER\"]}'\n",
        "    print(\"Using local Colab storage.\")\n",
        "\n",
        "# --- Construct Suffixes ---\n",
        "# Suffix for *this* run's output if supplementing refs\n",
        "generated_suffix = \"-generated\" if USE_GENERATED_REF_IMAGE else \"\"\n",
        "# Suffix based on precision setting\n",
        "precision_suffix = \"-fp32\" if USE_FP32 else \"\"\n",
        "\n",
        "# --- Define Current Run's Output Paths ---\n",
        "OUTPUT_DIR = f\"{base_output_prefix}-model{generated_suffix}{precision_suffix}\"\n",
        "OUTPUT_IMG_DIR = f\"{base_output_prefix}-results{generated_suffix}{precision_suffix}\"\n",
        "os.environ[\"OUTPUT_DIR\"] = OUTPUT_DIR  # For potential use by training scripts\n",
        "os.environ[\"OUTPUT_IMG_DIR\"] = OUTPUT_IMG_DIR  # For potential use by training scripts\n",
        "\n",
        "# --- Define Dataset/Input Paths ---\n",
        "# Uses Pathlib for easier handling\n",
        "TRAIN_DIR = Path(f'{os.environ[\"DATASET\"]}/{os.environ[\"BENCHMARK\"]}/{os.environ[\"DATASET_NUMBER\"]}')\n",
        "VAL_IMG = TRAIN_DIR / \"target/target.png\"\n",
        "VAL_MASK = TRAIN_DIR / \"target/mask.png\"\n",
        "# REF_DIR is the TARGET directory for the LoFTR script's copy operation\n",
        "REF_DIR = TRAIN_DIR / \"ref\"\n",
        "\n",
        "# Set corresponding environment variables if other scripts need them\n",
        "os.environ[\"TRAIN_DIR\"] = str(TRAIN_DIR)\n",
        "os.environ[\"VAL_IMG\"] = str(VAL_IMG)\n",
        "os.environ[\"VAL_MASK\"] = str(VAL_MASK)\n",
        "\n",
        "# --- Define SOURCE Directory for Candidate Images (Input for LoFTR script) ---\n",
        "# This is the results dir from the *previous* (non-generated) run\n",
        "SOURCE_RESULTS_DIR_FOR_COPY = f\"{base_output_prefix}-results{precision_suffix}\"\n",
        "\n",
        "# --- Create Necessary Directories ---\n",
        "# Ensure dataset, reference, and output directories exist\n",
        "TRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "REF_DIR.mkdir(parents=True, exist_ok=True)  # MUST exist before script runs\n",
        "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(OUTPUT_IMG_DIR).mkdir(parents=True, exist_ok=True)\n",
        "# Note: The script itself checks if SOURCE_RESULTS_DIR_FOR_COPY exists\n",
        "\n",
        "print(\"\\n--- Paths Initialized ---\")\n",
        "print(f\"Model Output Dir: {OUTPUT_DIR}\")\n",
        "print(f\"Results Output Dir: {OUTPUT_IMG_DIR}\")\n",
        "print(f\"Reference Dir (Target): {REF_DIR}\")\n",
        "print(f\"Source Candidates Dir: {SOURCE_RESULTS_DIR_FOR_COPY}\")\n",
        "\n",
        "# Conditional Reference Image Supplementing\n",
        "# If `USE_GENERATED_REF_IMAGE` is True, executes `loftr_ranking.py` to rank candidates\n",
        "# from the source directory against existing references and copy the best ones.\n",
        "\n",
        "if USE_GENERATED_REF_IMAGE:\n",
        "    print(\"\\n\" + \"=\" * 40)\n",
        "    print(f\"Calling LoFTR Ranking Script: {LOFTR_SCRIPT_PATH}\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Basic checks before executing the external script\n",
        "    if not os.path.exists(LOFTR_SCRIPT_PATH):\n",
        "        print(f\"ERROR: Cannot execute script. {LOFTR_SCRIPT_PATH} not found!\")\n",
        "        print(\"Please ensure the script is in the current directory or fix the path.\")\n",
        "    elif not REF_DIR.is_dir():\n",
        "        print(f\"ERROR: Target Reference directory '{REF_DIR}' does not exist. Skipping script.\")\n",
        "    else:\n",
        "        # Construct the command arguments safely using quotes\n",
        "        command = f\"\"\"python3 \"{LOFTR_SCRIPT_PATH}\" \\\n",
        "        --source-dir \"{SOURCE_RESULTS_DIR_FOR_COPY}\" \\\n",
        "        --ref-dir \"{str(REF_DIR)}\" \\\n",
        "        --target-count {TARGET_TOTAL_REF_COUNT}\n",
        "        \"\"\"\n",
        "        # Optional: Add arguments like --conf-threshold 0.8 if needed\n",
        "        # command += \" --conf-threshold 0.8\"\n",
        "\n",
        "        print(f\"Executing command:\\n{command}\\n\")\n",
        "        # Execute the command - output will be shown below\n",
        "        !{command}\n",
        "        print(\"\\nLoFTR Ranking Script Execution Finished.\")\n",
        "\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping reference image supplementing (USE_GENERATED_REF_IMAGE is False).\")\n",
        "\n",
        "\n",
        "# Final Environment Setup and Summary\n",
        "# Sets the precision argument and prints a summary of the final configuration.\n",
        "\n",
        "# Set precision argument for potential use in training scripts\n",
        "os.environ[\"PRECISION_ARG\"] = \"--mixed_precision=fp16\" if not USE_FP32 else \"\"\n",
        "\n",
        "# --- Print Final Summary ---\n",
        "print(\"\\n\" + \"*\" * 40)\n",
        "print(\"Final Configuration Summary\")\n",
        "print(\"*\" * 40)\n",
        "print(f\"Storage Location: {'Google Drive' if USE_DRIVE_STORAGE else 'Local Colab'}\")\n",
        "print(f\"Supplement References Script Called: {USE_GENERATED_REF_IMAGE}\")\n",
        "print(f\"Precision: {'FP16 (Mixed)' if not USE_FP32 else 'FP32'}\")\n",
        "print(f\"Precision Script Arg: {os.environ.get('PRECISION_ARG', '(Default)')}\")\n",
        "print(\"-\" * 10)\n",
        "print(f\"Model Output Dir: {os.environ['OUTPUT_DIR']}\")\n",
        "print(f\"Results Output Dir: {os.environ['OUTPUT_IMG_DIR']}\")\n",
        "print(\"-\" * 10)\n",
        "print(f\"Train Data Dir: {os.environ['TRAIN_DIR']}\")\n",
        "print(f\"Reference Dir (Final State): {REF_DIR} (Verify content)\")  # Remind user to check\n",
        "print(f\"Validation Image: {os.environ['VAL_IMG']}\")\n",
        "print(f\"Validation Mask: {os.environ['VAL_MASK']}\")\n",
        "print(\"*\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQexbUktpzdp"
      },
      "outputs": [],
      "source": [
        "!accelerate launch train_realfill.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --train_data_dir=$TRAIN_DIR \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=16 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --unet_learning_rate=2e-4 \\\n",
        "  --text_encoder_learning_rate=4e-5 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=100 \\\n",
        "  --max_train_steps=2000 \\\n",
        "  --lora_rank=8 \\\n",
        "  --lora_dropout=0.1 \\\n",
        "  --lora_alpha=16 \\\n",
        "  --resume_from_checkpoint=\"latest\" \\\n",
        "  --report_to tensorboard \\\n",
        "  --validation_steps 100 \\\n",
        "  --checkpointing_steps 100 \\\n",
        "  $PRECISION_ARG \\\n",
        "  --use_8bit_adam \\\n",
        "  --set_grads_to_none \\\n",
        "  --enable_xformers_memory_efficient_attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m023PQGd_H1"
      },
      "outputs": [],
      "source": [
        "!accelerate launch infer.py \\\n",
        "    --model_path=$OUTPUT_DIR \\\n",
        "    --validation_image=$VAL_IMG \\\n",
        "    --validation_mask=$VAL_MASK \\\n",
        "    --output_dir=$OUTPUT_IMG_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm40ryltdVNF"
      },
      "outputs": [],
      "source": [
        "# Zip final inference results\n",
        "!zip -r9j $OUTPUT_IMG_DIR.zip $OUTPUT_IMG_DIR\n",
        "# Zip tensorboard logs\n",
        "!zip -r9D $OUTPUT_DIR-tensorboard.zip $OUTPUT_DIR/logs\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eOMDzalXTvPh",
        "outputId": "af067d17-ddcb-4060-f60e-b1ece6e1e1de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing benchmarking requirements...\n",
            "\u001b[2mUsing Python 3.11.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mResolved \u001b[1m57 packages\u001b[0m \u001b[2min 798ms\u001b[0m\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dreamsim\u001b[2m==0.2.1\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m open-clip-torch \u001b[2m(1.5MiB)\u001b[0m\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m open-clip-torch\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dreamsim\u001b[2m==0.2.1\u001b[0m\n",
            "\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 609ms\u001b[0m\u001b[0m\n",
            "\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdreamsim\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlpips\u001b[0m\u001b[2m==0.1.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopen-clip-torch\u001b[0m\u001b[2m==2.32.0\u001b[0m\n",
            "\u001b[2mUsing Python 3.11.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mResolved \u001b[1m27 packages\u001b[0m \u001b[2min 720ms\u001b[0m\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m27 packages\u001b[0m \u001b[2min 0.18ms\u001b[0m\u001b[0m\n",
            "Benchmarking requirements installed.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies specifically for benchmarking\n",
        "print(\"Installing benchmarking requirements...\")\n",
        "!uv pip install -r requirements-benchmarks.txt --no-progress\n",
        "!uv pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124 --no-progress\n",
        "print(\"Benchmarking requirements installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qx7O_BQQTvPh"
      },
      "outputs": [],
      "source": [
        "# Make sure you mounted your Google Drive if using it!\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os  # Ensure os is imported if not already\n",
        "\n",
        "# --- Define paths for the benchmark script ---\n",
        "# Ensure these variables are correctly set based on your notebook's setup cell\n",
        "drive_base_dir = os.environ.get(\"DRIVE_BASE_DIR\", \"/content/drive/MyDrive/RealFill\")\n",
        "\n",
        "# --- !!! Define the correct locations for your UNZIPPED datasets !!! ---\n",
        "realbench_dataset_location = \"/content/realfill/realfill_data_release_full\" # Default download location\n",
        "custom_dataset_location = \"/content/realfill/jensen_images\"          # Default download location for custom/jensen\n",
        "\n",
        "benchmark_cache_dir = os.path.join(drive_base_dir, \"benchmark_cache\")\n",
        "benchmark_report_file = os.path.join(drive_base_dir, \"benchmark_report.txt\")\n",
        "loftr_script = \"loftr_ranking.py\"  # Assuming it's in the root directory\n",
        "\n",
        "print(\"\\n--- Running Benchmarks ---\")\n",
        "print(f\"Using Results Base: {drive_base_dir}\")\n",
        "print(f\"Using RealBench Dataset Dir: {realbench_dataset_location}\")\n",
        "print(f\"Using Custom Dataset Dir: {custom_dataset_location}\")\n",
        "print(f\"Using Cache Dir: {benchmark_cache_dir}\")\n",
        "print(f\"Saving Report To: {benchmark_report_file}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Construct the command, adding the new dataset directory arguments\n",
        "benchmark_command = f\"\"\"python benchmarks.py \\\\\n",
        "    --results_base_dir \"{drive_base_dir}\" \\\\\n",
        "    --realbench_dataset_dir \"{realbench_dataset_location}\" \\\\\n",
        "    --custom_dataset_dir \"{custom_dataset_location}\" \\\\\n",
        "    --cache_dir \"{benchmark_cache_dir}\" \\\\\n",
        "    --output_file \"{benchmark_report_file}\" \\\\\n",
        "    --loftr_script_path \"{loftr_script}\"\n",
        "\"\"\"\n",
        "# Optional: Add --force_recalc all or --metrics PSNR SSIM etc.\n",
        "# benchmark_command += \" --force_recalc all\"\n",
        "\n",
        "print(f\"Executing command:\\n{benchmark_command}\\n\")\n",
        "\n",
        "# Execute the benchmark script\n",
        "!{benchmark_command}\n",
        "\n",
        "print(\"\\n--- Benchmarking Script Finished ---\")\n",
        "print(f\"Report saved to: {benchmark_report_file}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}