{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eric15342335/realfill/blob/main/train_realfill.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7M37t-cRkNDf",
        "outputId": "df4f5934-5a89-465f-9bff-7da9c2b1f965",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'realfill'...\n",
            "remote: Enumerating objects: 316, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 316 (delta 68), reused 35 (delta 28), pack-reused 216 (from 1)\u001b[K\n",
            "Receiving objects: 100% (316/316), 1.29 MiB | 23.94 MiB/s, done.\n",
            "Resolving deltas: 100% (139/139), done.\n",
            "/content/realfill\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/eric15342335/realfill\n",
        "%cd realfill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vmLsetScrhad",
        "outputId": "512a4dae-8950-4d1f-a81c-074577c7db32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  452M  100  452M    0     0  66.8M      0  0:00:06  0:00:06 --:--:-- 42.9M\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://github.com/eric15342335/realfill/releases/download/dataset/realfill_data_release_full.zip -o realfill_data_release_full.zip\n",
        "!unzip -q realfill_data_release_full.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L https://github.com/eric15342335/realfill/releases/download/dataset/jensen_images.zip -o jensen_images.zip\n",
        "!unzip -q jensen_images.zip"
      ],
      "metadata": {
        "id": "rXUagDd5A69z",
        "outputId": "31ce2687-9619-43ed-cb17-10fef70b2ed9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 43.5M  100 43.5M    0     0  38.0M      0  0:00:01  0:00:01 --:--:-- 82.0M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wTXUPQrrtMZF",
        "outputId": "209718a7-d9d3-4b6a-f793-41cda19ca97f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 497M\n",
            "drwxr-xr-x 4 root root 4.0K Apr 22 13:56 \u001b[0m\u001b[01;34mdata\u001b[0m/\n",
            "-rw-r--r-- 1 root root 3.4K Apr 22 13:56 infer.py\n",
            "drwxr-xr-x 3 root root 4.0K Apr 22 00:01 \u001b[01;34mjensen_images\u001b[0m/\n",
            "-rw-r--r-- 1 root root  44M Apr 22 13:56 jensen_images.zip\n",
            "-rw-r--r-- 1 root root 1.1K Apr 22 13:56 LICENSE\n",
            "drwxr-xr-x 3 root root 4.0K Apr 22 13:56 \u001b[01;34m__MACOSX\u001b[0m/\n",
            "-rw-r--r-- 1 root root  383 Apr 22 13:56 README.md\n",
            "-rw-r--r-- 1 root root 5.9K Apr 22 13:56 README-Realfill.md\n",
            "drwxr-xr-x 4 root root 4.0K May 30  2024 \u001b[01;34mrealfill_data_release_full\u001b[0m/\n",
            "-rw-r--r-- 1 root root 453M Apr 22 13:56 realfill_data_release_full.zip\n",
            "-rw-r--r-- 1 root root  119 Apr 22 13:56 requirements.txt\n",
            "-rw-r--r-- 1 root root  26K Apr 22 13:56 train_realfill.ipynb\n",
            "-rw-r--r-- 1 root root  37K Apr 22 13:56 train_realfill.py\n"
          ]
        }
      ],
      "source": [
        "%pwd\n",
        "%ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hcWLJk3kq3i",
        "outputId": "711b5889-ff70-42b5-bb10-3a022938711f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mResolved \u001b[1m58 packages\u001b[0m \u001b[2min 454ms\u001b[0m\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cusparse-cu12 \u001b[2m(197.8MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cublas-cu12 \u001b[2m(346.6MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m diffusers \u001b[2m(3.4MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-nvjitlink-cu12 \u001b[2m(20.1MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m setuptools \u001b[2m(1.2MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pillow \u001b[2m(4.4MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cusolver-cu12 \u001b[2m(122.0MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m numpy \u001b[2m(15.7MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cuda-nvrtc-cu12 \u001b[2m(23.5MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cuda-cupti-cu12 \u001b[2m(13.2MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m tensorboard \u001b[2m(5.2MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cudnn-cu12 \u001b[2m(634.0MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-cufft-cu12 \u001b[2m(201.7MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m bitsandbytes \u001b[2m(72.5MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m nvidia-curand-cu12 \u001b[2m(53.7MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m xformers \u001b[2m(41.4MiB)\u001b[0m\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m setuptools\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m pillow\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m diffusers\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m tensorboard\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cuda-cupti-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-nvjitlink-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cuda-nvrtc-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m numpy\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m xformers\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-curand-cu12\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m bitsandbytes\n",
            " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m nvidia-cusolver-cu12\n"
          ]
        }
      ],
      "source": [
        "!uv pip install -U -r requirements.txt --no-progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYgiy8a9k5yA"
      },
      "outputs": [],
      "source": [
        "from accelerate.utils import write_basic_config\n",
        "write_basic_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaqFewZMrhae"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Toggle switch - set to True for Google Drive storage, False for local storage\n",
        "USE_DRIVE_STORAGE = True\n",
        "# --- Precision Toggles ---\n",
        "# Set only ONE of these to True, or both to False for FP16\n",
        "USE_FP32 = False # Highest precedence: If True, uses FP32\n",
        "USE_BF16 = True # Second precedence: If True (and USE_FP32 is False), uses BF16\n",
        "# If both USE_FP32 and USE_BF16 are False, uses FP16\n",
        "\n",
        "# --- Determine Active Precision ---\n",
        "if USE_FP32:\n",
        "    active_precision = \"fp32\"\n",
        "elif USE_BF16:\n",
        "    active_precision = \"bf16\"\n",
        "else:\n",
        "    active_precision = \"fp16\" # Default if both toggles are False\n",
        "\n",
        "# Base directory for Google Drive storage\n",
        "DRIVE_BASE_DIR = \"/content/drive/MyDrive/RealFill\"\n",
        "\n",
        "# Keep your original environment variable setup\n",
        "os.environ[\"DATASET\"] = \"realfill_data_release_full\" # realfill_data_release_full, jensen_images\n",
        "os.environ[\"MODEL_NAME\"] = \"stabilityai/stable-diffusion-2-inpainting\"\n",
        "os.environ[\"BENCHMARK\"] = \"RealBench\"  # RealBench, Qualitative, Custom\n",
        "os.environ[\"DATASET_NUMBER\"] = \"24\"\n",
        "\n",
        "# Construct paths based on the storage toggle\n",
        "if USE_DRIVE_STORAGE:\n",
        "    # Use Google Drive for storage\n",
        "    # Make sure drive is mounted if needed (place this where appropriate in your Colab flow)\n",
        "    try:\n",
        "        from google.colab import drive # Check if in Colab\n",
        "        drive.mount('/content/drive', force_remount=True) # Added force_remount for convenience\n",
        "    except ImportError:\n",
        "        print(\"Not running in Google Colab or drive import failed. Assuming local paths for DRIVE_BASE_DIR.\")\n",
        "        # Potentially fall back to local or handle error depending on expected environment\n",
        "    base_output_prefix = f'{DRIVE_BASE_DIR}/{os.environ[\"BENCHMARK\"]}-{os.environ[\"DATASET_NUMBER\"]}'\n",
        "else:\n",
        "    # Use local storage (e.g., Colab ephemeral storage or local machine)\n",
        "    base_output_prefix = f'{os.environ[\"BENCHMARK\"]}-{os.environ[\"DATASET_NUMBER\"]}'\n",
        "\n",
        "# --- Construct suffix for directories based on active precision ---\n",
        "# Append suffix only for non-default precisions (FP32, BF16)\n",
        "precision_suffix = \"\"\n",
        "if active_precision == \"fp32\":\n",
        "    precision_suffix = \"-fp32\"\n",
        "elif active_precision == \"bf16\":\n",
        "    precision_suffix = \"-bf16\"\n",
        "\n",
        "# --- Set output paths using the determined suffix ---\n",
        "os.environ[\"OUTPUT_DIR\"] = f'{base_output_prefix}-model{precision_suffix}'\n",
        "os.environ[\"OUTPUT_IMG_DIR\"] = f'{base_output_prefix}-results{precision_suffix}'\n",
        "\n",
        "# --- Set paths for training data and validation images ---\n",
        "os.environ[\"TRAIN_DIR\"] = f'{os.environ[\"DATASET\"]}/{os.environ[\"BENCHMARK\"]}/{os.environ[\"DATASET_NUMBER\"]}'\n",
        "# Ensure TRAIN_DIR exists relative to the potential drive mount or local path\n",
        "# This assumes DATASET directory is at the root or accessible from DRIVE_BASE_DIR\n",
        "# Adjust if your DATASET path depends on USE_DRIVE_STORAGE\n",
        "if USE_DRIVE_STORAGE and not os.path.exists(os.environ[\"TRAIN_DIR\"]):\n",
        "     # Example: If DATASET path is also on Drive relative to DRIVE_BASE_DIR's parent\n",
        "     potential_train_dir_on_drive = os.path.join(DRIVE_BASE_DIR, \"..\", os.environ[\"DATASET\"], os.environ[\"BENCHMARK\"], os.environ[\"DATASET_NUMBER\"])\n",
        "     if os.path.exists(potential_train_dir_on_drive):\n",
        "           os.environ[\"TRAIN_DIR\"] = potential_train_dir_on_drive\n",
        "     # Add more logic here if TRAIN_DIR location is complex\n",
        "\n",
        "os.environ[\"VAL_IMG\"] = os.path.join(os.environ[\"TRAIN_DIR\"], 'target', 'target.png')\n",
        "os.environ[\"VAL_MASK\"] = os.path.join(os.environ[\"TRAIN_DIR\"], 'target', 'mask.png')\n",
        "\n",
        "\n",
        "# Create the necessary output directories\n",
        "os.makedirs(os.environ[\"OUTPUT_DIR\"], exist_ok=True)\n",
        "os.makedirs(os.environ[\"OUTPUT_IMG_DIR\"], exist_ok=True)\n",
        "\n",
        "# --- Set the shell environment variable for the training script ---\n",
        "# This makes the variable available to the subshell created by !\n",
        "# Assumes the training script uses `--mixed_precision=bf16` or `--mixed_precision=fp16`\n",
        "# and no argument (or perhaps --mixed_precision=no) for FP32.\n",
        "if active_precision == \"fp32\":\n",
        "    os.environ['PRECISION_ARG'] = '' # Empty for FP32\n",
        "elif active_precision == \"bf16\":\n",
        "    os.environ['PRECISION_ARG'] = '--mixed_precision=bf16'\n",
        "else: # fp16\n",
        "    os.environ['PRECISION_ARG'] = '--mixed_precision=fp16'\n",
        "\n",
        "# --- Print Statements ---\n",
        "print(f\"Using {'Google Drive' if USE_DRIVE_STORAGE else 'local'} storage\")\n",
        "print(f\"Selected Training Precision: {active_precision.upper()}\")\n",
        "print(f\"Train directory: {os.environ['TRAIN_DIR']}\")\n",
        "print(f\"Validation Image: {os.environ['VAL_IMG']}\")\n",
        "print(f\"Validation Mask: {os.environ['VAL_MASK']}\")\n",
        "print(f\"Output Model directory: {os.environ['OUTPUT_DIR']}\")\n",
        "print(f\"Output Results directory: {os.environ['OUTPUT_IMG_DIR']}\")\n",
        "print(f\"Precision argument for script: '{os.environ['PRECISION_ARG']}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQexbUktpzdp"
      },
      "outputs": [],
      "source": [
        "!accelerate launch train_realfill.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --train_data_dir=$TRAIN_DIR \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=16 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --unet_learning_rate=2e-4 \\\n",
        "  --text_encoder_learning_rate=4e-5 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=100 \\\n",
        "  --max_train_steps=2000 \\\n",
        "  --lora_rank=8 \\\n",
        "  --lora_dropout=0.1 \\\n",
        "  --lora_alpha=16 \\\n",
        "  --resume_from_checkpoint=\"latest\" \\\n",
        "  --report_to tensorboard \\\n",
        "  --validation_steps 100 \\\n",
        "  --checkpointing_steps 100 \\\n",
        "  $PRECISION_ARG \\\n",
        "  --use_8bit_adam \\\n",
        "  --set_grads_to_none \\\n",
        "  --enable_xformers_memory_efficient_attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m023PQGd_H1"
      },
      "outputs": [],
      "source": [
        "!accelerate launch infer.py \\\n",
        "    --model_path=$OUTPUT_DIR \\\n",
        "    --validation_image=$VAL_IMG \\\n",
        "    --validation_mask=$VAL_MASK \\\n",
        "    --output_dir=$OUTPUT_IMG_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm40ryltdVNF"
      },
      "outputs": [],
      "source": [
        "# Zip final inference results\n",
        "!zip -r9j $OUTPUT_IMG_DIR.zip $OUTPUT_IMG_DIR\n",
        "# Zip tensorboard logs\n",
        "!zip -r9D $OUTPUT_DIR-tensorboard.zip $OUTPUT_DIR/logs\n",
        "%ls"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}