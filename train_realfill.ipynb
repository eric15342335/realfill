{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eric15342335/realfill/blob/main/train_realfill.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M37t-cRkNDf",
        "outputId": "c2bb7fb7-0b2c-4d4c-9efc-6bd18232e221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'realfill'...\n",
            "remote: Enumerating objects: 295, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 295 (delta 54), reused 37 (delta 28), pack-reused 216 (from 1)\u001b[K\n",
            "Receiving objects: 100% (295/295), 1.27 MiB | 3.19 MiB/s, done.\n",
            "Resolving deltas: 100% (125/125), done.\n",
            "/content/realfill\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/eric15342335/realfill\n",
        "%cd realfill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmLsetScrhad",
        "outputId": "cc19906f-0e3a-4bef-97ef-ee236bb14865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  452M  100  452M    0     0  40.4M      0  0:00:11  0:00:11 --:--:-- 43.3M\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://github.com/eric15342335/realfill/releases/download/dataset/realfill_data_release_full.zip -o realfill_data_release_full.zip\n",
        "!unzip -q realfill_data_release_full.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTXUPQrrtMZF",
        "outputId": "fd89b574-7c77-4a0f-c81b-9022b5d994e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 454M\n",
            "drwxr-xr-x 4 root root 4.0K Apr 19 16:34 \u001b[0m\u001b[01;34mdata\u001b[0m/\n",
            "-rw-r--r-- 1 root root 2.5K Apr 19 16:34 infer.py\n",
            "-rw-r--r-- 1 root root 1.1K Apr 19 16:34 LICENSE\n",
            "drwxr-xr-x 3 root root 4.0K Apr 19 16:34 \u001b[01;34m__MACOSX\u001b[0m/\n",
            "-rw-r--r-- 1 root root  383 Apr 19 16:34 README.md\n",
            "-rw-r--r-- 1 root root 5.9K Apr 19 16:34 README-Realfill.md\n",
            "drwxr-xr-x 4 root root 4.0K May 30  2024 \u001b[01;34mrealfill_data_release_full\u001b[0m/\n",
            "-rw-r--r-- 1 root root 453M Apr 19 16:34 realfill_data_release_full.zip\n",
            "-rw-r--r-- 1 root root  119 Apr 19 16:34 requirements.txt\n",
            "-rw-r--r-- 1 root root  28K Apr 19 16:34 train_realfill.ipynb\n",
            "-rw-r--r-- 1 root root  37K Apr 19 16:34 train_realfill.py\n"
          ]
        }
      ],
      "source": [
        "%pwd\n",
        "%ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hcWLJk3kq3i",
        "outputId": "9ccfd1ce-292c-48a5-fe55-6d147c79d61d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (0.32.2)\n",
            "Collecting diffusers (from -r requirements.txt (line 1))\n",
            "  Downloading diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.5.2)\n",
            "Collecting accelerate (from -r requirements.txt (line 2))\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.51.3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.14.0)\n",
            "Collecting peft (from -r requirements.txt (line 4))\n",
            "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.30.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.21.0+cu124)\n",
            "Collecting ftfy (from -r requirements.txt (line 8))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.18.0)\n",
            "Collecting tensorboard (from -r requirements.txt (line 9))\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (3.1.6)\n",
            "Collecting bitsandbytes (from -r requirements.txt (line 11))\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting xformers (from -r requirements.txt (line 12))\n",
            "  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->-r requirements.txt (line 1)) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers->-r requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers->-r requirements.txt (line 1)) (11.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (0.21.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r requirements.txt (line 5)) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r requirements.txt (line 5)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->-r requirements.txt (line 8)) (0.2.13)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2->-r requirements.txt (line 10)) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers->-r requirements.txt (line 1)) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->-r requirements.txt (line 1)) (2025.1.31)\n",
            "Downloading diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
            "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, tensorboard, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, diffusers, xformers, bitsandbytes, accelerate, peft\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.32.2\n",
            "    Uninstalling diffusers-0.32.2:\n",
            "      Successfully uninstalled diffusers-0.32.2\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.5.2\n",
            "    Uninstalling accelerate-1.5.2:\n",
            "      Successfully uninstalled accelerate-1.5.2\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-1.6.0 bitsandbytes-0.45.5 diffusers-0.33.1 ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.15.2 tensorboard-2.19.0 xformers-0.0.29.post3\n"
          ]
        }
      ],
      "source": [
        "%pip install -U -r requirements.txt --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYgiy8a9k5yA",
        "outputId": "25512948-050c-41fd-fdd2-f18a3b0108c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.cache/huggingface/accelerate/default_config.yaml')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from accelerate.utils import write_basic_config\n",
        "write_basic_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaqFewZMrhae",
        "outputId": "4e6438ee-3b27-47a9-e121-e9dc12e56eff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using Google Drive storage\n",
            "Output directory: /content/drive/MyDrive/RealFill/RealBench-23-model\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Toggle switch - set to True for Google Drive storage, False for local storage\n",
        "USE_DRIVE_STORAGE = True\n",
        "\n",
        "# Base directory for Google Drive storage\n",
        "DRIVE_BASE_DIR = \"/content/drive/MyDrive/RealFill\"\n",
        "\n",
        "# Keep your original environment variable setup\n",
        "os.environ[\"DATASET\"] = \"realfill_data_release_full\"\n",
        "os.environ[\"MODEL_NAME\"] = \"stabilityai/stable-diffusion-2-inpainting\"\n",
        "os.environ[\"BENCHMARK\"] = \"RealBench\"  # Replace with \"Qualitative\" if needed\n",
        "os.environ[\"DATASET_NUMBER\"] = \"23\"\n",
        "\n",
        "# Construct paths based on the storage toggle\n",
        "if USE_DRIVE_STORAGE:\n",
        "    # Use Google Drive for storage\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    os.environ[\"OUTPUT_DIR\"] = f'{DRIVE_BASE_DIR}/{os.environ[\"BENCHMARK\"]}-{os.environ[\"DATASET_NUMBER\"]}-model'\n",
        "    os.environ[\"OUTPUT_IMG_DIR\"] = f'{DRIVE_BASE_DIR}/{os.environ[\"BENCHMARK\"]}-{os.environ[\"DATASET_NUMBER\"]}-results'\n",
        "else:\n",
        "    # Use local Colab storage (original paths)\n",
        "    os.environ[\"OUTPUT_DIR\"] = f'{os.environ[\"BENCHMARK\"]}-{os.environ[\"DATASET_NUMBER\"]}-model'\n",
        "    os.environ[\"OUTPUT_IMG_DIR\"] = f'{os.environ[\"BENCHMARK\"]}-{os.environ[\"DATASET_NUMBER\"]}-results'\n",
        "\n",
        "# The remaining variable paths stay the same\n",
        "os.environ[\"TRAIN_DIR\"] = f'{os.environ[\"DATASET\"]}/{os.environ[\"BENCHMARK\"]}/{os.environ[\"DATASET_NUMBER\"]}'\n",
        "os.environ[\"VAL_IMG\"] = f'{os.environ[\"TRAIN_DIR\"]}/target/target.png'\n",
        "os.environ[\"VAL_MASK\"] = f'{os.environ[\"TRAIN_DIR\"]}/target/mask.png'\n",
        "\n",
        "# Create the necessary directories\n",
        "os.makedirs(os.environ[\"OUTPUT_DIR\"], exist_ok=True)\n",
        "os.makedirs(os.environ[\"OUTPUT_IMG_DIR\"], exist_ok=True)\n",
        "\n",
        "print(f\"Using {'Google Drive' if USE_DRIVE_STORAGE else 'local Colab'} storage\")\n",
        "print(f\"Output directory: {os.environ['OUTPUT_DIR']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQexbUktpzdp",
        "outputId": "a081eb42-65e4-4656-cddf-5dadc0473794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-19 16:38:57.129921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745080737.160963    2569 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745080737.169301    2569 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-19 16:38:57.189322: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "04/19/2025 16:39:01 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "{'prediction_type', 'timestep_spacing', 'rescale_betas_zero_snr', 'variance_type', 'clip_sample_range', 'dynamic_thresholding_ratio', 'thresholding', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "{'scaling_factor', 'force_upcast', 'mid_block_add_attention', 'use_post_quant_conv', 'latents_std', 'latents_mean', 'shift_factor', 'use_quant_conv'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at stabilityai/stable-diffusion-2-inpainting.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "{'upcast_attention', 'conv_out_kernel', 'cross_attention_norm', 'time_embedding_act_fn', 'mid_block_type', 'attention_type', 'encoder_hid_dim', 'num_class_embeds', 'encoder_hid_dim_type', 'dropout', 'time_embedding_type', 'num_attention_heads', 'resnet_skip_time_act', 'conv_in_kernel', 'projection_class_embeddings_input_dim', 'only_cross_attention', 'transformer_layers_per_block', 'mid_block_only_cross_attention', 'reverse_transformer_layers_per_block', 'class_embeddings_concat', 'class_embed_type', 'resnet_time_scale_shift', 'timestep_post_act', 'time_embedding_dim', 'addition_time_embed_dim', 'time_cond_proj_dim', 'addition_embed_type_num_heads', 'resnet_out_scale_factor', 'addition_embed_type'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing UNet2DConditionModel.\n",
            "\n",
            "All the weights of UNet2DConditionModel were initialized from the model checkpoint at stabilityai/stable-diffusion-2-inpainting.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n",
            "04/19/2025 16:39:23 - INFO - __main__ - ***** Running training *****\n",
            "04/19/2025 16:39:23 - INFO - __main__ -   Num examples = 5\n",
            "04/19/2025 16:39:23 - INFO - __main__ -   Num batches each epoch = 1\n",
            "04/19/2025 16:39:23 - INFO - __main__ -   Num Epochs = 2000\n",
            "04/19/2025 16:39:23 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "04/19/2025 16:39:23 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "04/19/2025 16:39:23 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "04/19/2025 16:39:23 - INFO - __main__ -   Total optimization steps = 2000\n",
            "Checkpoint 'latest' does not exist. Starting a new training run.\n",
            "Steps:   1% 18/2000 [00:47<1:23:33,  2.53s/it, loss=0.0862]"
          ]
        }
      ],
      "source": [
        "!accelerate launch train_realfill.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --train_data_dir=$TRAIN_DIR \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=16 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --unet_learning_rate=2e-4 \\\n",
        "  --text_encoder_learning_rate=4e-5 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=100 \\\n",
        "  --max_train_steps=2000 \\\n",
        "  --lora_rank=8 \\\n",
        "  --lora_dropout=0.1 \\\n",
        "  --lora_alpha=16 \\\n",
        "  --resume_from_checkpoint=\"latest\" \\\n",
        "  --report_to tensorboard \\\n",
        "  --validation_steps 100 \\\n",
        "  --checkpointing_steps 100 \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --set_grads_to_none \\\n",
        "  --enable_xformers_memory_efficient_attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m023PQGd_H1"
      },
      "outputs": [],
      "source": [
        "!accelerate launch infer.py \\\n",
        "    --model_path=$OUTPUT_DIR \\\n",
        "    --validation_image=$VAL_IMG \\\n",
        "    --validation_mask=$VAL_MASK \\\n",
        "    --output_dir=$OUTPUT_IMG_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm40ryltdVNF"
      },
      "outputs": [],
      "source": [
        "# Zip final inference results\n",
        "!zip -r $OUTPUT_IMG_DIR.zip $OUTPUT_IMG_DIR\n",
        "# Zip tensorboard logs\n",
        "!zip -r $OUTPUT_DIR-tensorboard.zip $OUTPUT_DIR/logs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}